{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ez1PZHtz76Yn"
      },
      "source": [
        "# Working with ChatGPT API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9D_UWEGa8Ek3"
      },
      "source": [
        "### Installing `openai` library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "O7fj9NSrITHR",
        "outputId": "b2248357-ce4c-4a97-9299-9ca9dbede1c6"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "from apikey import apikey"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDbBJ9qz8MZd"
      },
      "source": [
        "### Importing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "upPPfX_bLgyQ"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain, SequentialChain \n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.utilities import WikipediaAPIWrapper "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvP7UFYS8YlB"
      },
      "source": [
        "### Getting the API key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "EWcQcZUVvXxW"
      },
      "outputs": [],
      "source": [
        "os.environ['OPENAI_API_KEY'] = apikey\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugYS-nCX8ebk"
      },
      "source": [
        "### LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "WZ85-KlVb90v"
      },
      "outputs": [],
      "source": [
        "\n",
        "llm = OpenAI(temperature=0.9, max_tokens=100, top_p=1, frequency_penalty=0.0, presence_penalty=0.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55Rh68oM8ptk"
      },
      "source": [
        "### Function to call `Chat` class and simulate a conversation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "UdsfPKpBbpQ9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You entered: hello\n"
          ]
        }
      ],
      "source": [
        "user_unput = str(input(\"Enter your prompt: \"))\n",
        "print(\"You entered: \" + user_unput)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdbtOqDm809D"
      },
      "source": [
        "### Calling `simulate` function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmNq1n3Fkxc3",
        "outputId": "4f5270d2-a3bd-458b-8397-4589276383cd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unexpected exception formatting exception. Falling back to standard exception\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\aryan\\OneDrive\\Desktop\\DSC-Chatbot\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n",
            "  File \"C:\\Users\\aryan\\AppData\\Local\\Temp\\ipykernel_280\\195283022.py\", line 2, in <module>\n",
            "    response = llm(user_unput)\n",
            "               ^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\aryan\\OneDrive\\Desktop\\DSC-Chatbot\\venv\\Lib\\site-packages\\langchain\\llms\\base.py\", line 429, in __call__\n",
            "    self.generate(\n",
            "  File \"c:\\Users\\aryan\\OneDrive\\Desktop\\DSC-Chatbot\\venv\\Lib\\site-packages\\langchain\\llms\\base.py\", line 281, in generate\n",
            "    output = self._generate_helper(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\aryan\\OneDrive\\Desktop\\DSC-Chatbot\\venv\\Lib\\site-packages\\langchain\\llms\\base.py\", line 225, in _generate_helper\n",
            "    raise e\n",
            "  File \"c:\\Users\\aryan\\OneDrive\\Desktop\\DSC-Chatbot\\venv\\Lib\\site-packages\\langchain\\llms\\base.py\", line 212, in _generate_helper\n",
            "    self._generate(\n",
            "  File \"c:\\Users\\aryan\\OneDrive\\Desktop\\DSC-Chatbot\\venv\\Lib\\site-packages\\langchain\\llms\\openai.py\", line 319, in _generate\n",
            "    response = completion_with_retry(self, prompt=_prompts, **params)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\aryan\\OneDrive\\Desktop\\DSC-Chatbot\\venv\\Lib\\site-packages\\langchain\\llms\\openai.py\", line 89, in completion_with_retry\n",
            "    return _completion_with_retry(**kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\aryan\\OneDrive\\Desktop\\DSC-Chatbot\\venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 289, in wrapped_f\n",
            "    return self(f, *args, **kw)\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\aryan\\OneDrive\\Desktop\\DSC-Chatbot\\venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 379, in __call__\n",
            "    do = self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\aryan\\OneDrive\\Desktop\\DSC-Chatbot\\venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 325, in iter\n",
            "    raise retry_exc.reraise()\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\aryan\\OneDrive\\Desktop\\DSC-Chatbot\\venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 158, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Program Files\\Python311\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Program Files\\Python311\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"c:\\Users\\aryan\\OneDrive\\Desktop\\DSC-Chatbot\\venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 382, in __call__\n",
            "    result = fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\aryan\\OneDrive\\Desktop\\DSC-Chatbot\\venv\\Lib\\site-packages\\langchain\\llms\\openai.py\", line 87, in _completion_with_retry\n",
            "    return llm.client.create(**kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\aryan\\OneDrive\\Desktop\\DSC-Chatbot\\venv\\Lib\\site-packages\\openai\\api_resources\\completion.py\", line 25, in create\n",
            "    return super().create(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\aryan\\OneDrive\\Desktop\\DSC-Chatbot\\venv\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 153, in create\n",
            "    response, _, api_key = requestor.request(\n",
            "                           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\aryan\\OneDrive\\Desktop\\DSC-Chatbot\\venv\\Lib\\site-packages\\openai\\api_requestor.py\", line 298, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\aryan\\OneDrive\\Desktop\\DSC-Chatbot\\venv\\Lib\\site-packages\\openai\\api_requestor.py\", line 700, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"c:\\Users\\aryan\\OneDrive\\Desktop\\DSC-Chatbot\\venv\\Lib\\site-packages\\openai\\api_requestor.py\", line 763, in _interpret_response_line\n",
            "    raise self.handle_error_response(\n",
            "openai.error.RateLimitError: You exceeded your current quota, please check your plan and billing details.\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\aryan\\OneDrive\\Desktop\\DSC-Chatbot\\venv\\Lib\\site-packages\\pygments\\styles\\__init__.py\", line 89, in get_style_by_name\n",
            "ModuleNotFoundError: No module named 'pygments.styles.default'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\aryan\\OneDrive\\Desktop\\DSC-Chatbot\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2105, in showtraceback\n",
            "  File \"c:\\Users\\aryan\\OneDrive\\Desktop\\DSC-Chatbot\\venv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1428, in structured_traceback\n",
            "  File \"c:\\Users\\aryan\\OneDrive\\Desktop\\DSC-Chatbot\\venv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1319, in structured_traceback\n",
            "  File \"c:\\Users\\aryan\\OneDrive\\Desktop\\DSC-Chatbot\\venv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1172, in structured_traceback\n",
            "  File \"c:\\Users\\aryan\\OneDrive\\Desktop\\DSC-Chatbot\\venv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1062, in format_exception_as_a_whole\n",
            "  File \"c:\\Users\\aryan\\OneDrive\\Desktop\\DSC-Chatbot\\venv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1113, in get_records\n",
            "  File \"c:\\Users\\aryan\\OneDrive\\Desktop\\DSC-Chatbot\\venv\\Lib\\site-packages\\pygments\\styles\\__init__.py\", line 91, in get_style_by_name\n",
            "pygments.util.ClassNotFound: Could not find style module 'default', though it should be builtin.\n"
          ]
        }
      ],
      "source": [
        "if user_unput:\n",
        "    response = llm(user_unput)\n",
        "    print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtnQSC_e9jMs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
