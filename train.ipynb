{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/aryanraj/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/aryanraj/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file_path):\n",
    "    with open(\"intents.json\", \"r\") as file:\n",
    "        dataset = json.load(file)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(dataset):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    \n",
    "    for intent in dataset[\"intents\"]:\n",
    "        for pattern in intent[\"patterns\"]:\n",
    "            texts.append(pattern.lower())\n",
    "            labels.append(intent[\"tag\"])\n",
    "    \n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_vectorizer(texts):\n",
    "    vectorizer = CountVectorizer(lowercase=True, stop_words=nltk.corpus.stopwords.words(\"english\"))\n",
    "    vectorizer.fit(texts)\n",
    "    return vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_model(X_train, y_train):\n",
    "    model = MultinomialNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(dataset, vectorizer, model, user_input):\n",
    "    user_input = user_input.lower()\n",
    "    user_input_vector = vectorizer.transform([user_input])\n",
    "    predicted_class_index = model.predict(user_input_vector)[0]\n",
    "    predicted_class = model.classes_[predicted_class_index]\n",
    "\n",
    "    for intent in dataset[\"intents\"]:\n",
    "        if intent[\"tag\"] == predicted_class:\n",
    "            response = random.choice(intent[\"responses\"])\n",
    "            return response\n",
    "\n",
    "    return \"I'm sorry, I don't understand. Can you rephrase that?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(dataset, vectorizer, model):\n",
    "    print(\"Chatbot: Hi there! Welcome from team Data Science Community SRM?\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"You: \").lower()\n",
    "        \n",
    "        if user_input in ['exit', 'quit', 'bye', 'goodbye']:\n",
    "            print(\"Chatbot: Goodbye! Have a great day!\")\n",
    "            break\n",
    "\n",
    "        user_input_vector = vectorizer.transform([user_input])\n",
    "        predicted_class_index = model.predict(user_input_vector)[0]\n",
    "        predicted_class = classes[predicted_class_index]\n",
    "        \n",
    "        for intent in dataset[\"intents\"]:\n",
    "            if intent[\"tag\"] == predicted_class:\n",
    "                response = random.choice(intent[\"responses\"])\n",
    "                print(\"Chatbot:\", response)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Hi there! Welcome from team Data Science Community SRM?\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m model \u001b[39m=\u001b[39m create_model(X, y)\n\u001b[1;32m     10\u001b[0m classes \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mclasses_\n\u001b[0;32m---> 12\u001b[0m chat(dataset, vectorizer, model)\n",
      "Cell \u001b[0;32mIn[50], line 13\u001b[0m, in \u001b[0;36mchat\u001b[0;34m(dataset, vectorizer, model)\u001b[0m\n\u001b[1;32m     11\u001b[0m user_input_vector \u001b[39m=\u001b[39m vectorizer\u001b[39m.\u001b[39mtransform([user_input])\n\u001b[1;32m     12\u001b[0m predicted_class_index \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(user_input_vector)[\u001b[39m0\u001b[39m]\n\u001b[0;32m---> 13\u001b[0m predicted_class \u001b[39m=\u001b[39m classes[predicted_class_index]\n\u001b[1;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m intent \u001b[39min\u001b[39;00m dataset[\u001b[39m\"\u001b[39m\u001b[39mintents\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m     16\u001b[0m     \u001b[39mif\u001b[39;00m intent[\u001b[39m\"\u001b[39m\u001b[39mtag\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m predicted_class:\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    dataset = load_dataset(\"intents.json\")\n",
    "    texts, labels = preprocess_data(dataset)\n",
    "    \n",
    "    vectorizer = create_vectorizer(texts)\n",
    "    X = vectorizer.transform(texts)\n",
    "    y = np.array(labels)\n",
    "    \n",
    "    model = create_model(X, y)\n",
    "    classes = model.classes_\n",
    "    \n",
    "    chat(dataset, vectorizer, model)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "chat() missing 2 required positional arguments: 'vectorizer' and 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m chat(\u001b[39m\"\u001b[39;49m\u001b[39mwhat are the projects?\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: chat() missing 2 required positional arguments: 'vectorizer' and 'model'"
     ]
    }
   ],
   "source": [
    "chat(\"what are the projects?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
